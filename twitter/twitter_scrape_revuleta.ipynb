{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd82637-6ae7-4efa-9cf0-92c6ae359367",
   "metadata": {},
   "source": [
    "- Dues queries: `\"#LaRevuelta\"` i `\"@LaRevueltaTVE\"` per un seguit de franges temporals, fent servir `since:` i `until:`\n",
    "- Es crea un diccionari de respostes de l'API segons aquestes dates\n",
    "- Processament de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737a57f-505d-47e1-80b9-ec57b7a978f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from twitter_scrape_utils import setup_accounts, tweets2df\n",
    "from twscrape import API, gather\n",
    "from twscrape.logger import set_log_level\n",
    "\n",
    "set_log_level(\"DEBUG\")\n",
    "api = API()  # initialize the API with default account database `accounts.db`\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a020288-70ed-4254-9d79-0725b0c99c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "await setup_accounts(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ccb6d-f176-4265-a23e-5cbad2a55d9d",
   "metadata": {},
   "source": [
    "- màxim de 3 tweets per dia pel 2023 -> l'API s'ho passa pel forro\n",
    "- màxim de 2 respostes (que siguin del compte @RAEinforma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fde1f2-3db9-425d-8136-7371abf6dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime(2025, 1, 13)\n",
    "end_date = datetime(2025, 1, 19)\n",
    "\n",
    "date_queries = {}\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    since_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    until_date = (current_date + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    # query = f\"#LaRevuelta since:{since_date} until:{until_date}\"\n",
    "    query = f\"@LaRevuelta_TVE since:{since_date} until:{until_date}\"\n",
    "    date_queries[since_date] = query\n",
    "\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c1cc0-0535-4564-af19-453c98daed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e6951f-ecbb-406c-9ce8-d2ce9d515426",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = {}\n",
    "# Load already scrapped tweets\n",
    "# with open(\"tweets#.pkl\", \"rb\") as f:\n",
    "#     tweets = pickle.load(f)\n",
    "# with open(\"tweets@.pkl\", \"rb\") as f:\n",
    "#     tweets2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fcb36f-d779-40c6-ac2a-2e8bc40cc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, query in date_queries.items():\n",
    "    print(date)\n",
    "    if date in tweets:\n",
    "        continue\n",
    "    tweets[date] = await gather(api.search(query, limit=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8d0a3-3440-4b6d-a2c6-1786491091dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tweets.keys():\n",
    "    print(key, len(tweets[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eed3a1-ba90-476e-8cf8-ca93177921b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tweets\n",
    "# with open(\"tweets.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e6738-80f3-4191-9404-f14fd24e16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tweet(tweet):\n",
    "    return {\n",
    "        \"id\": tweet.id,\n",
    "        \"url\": tweet.url,\n",
    "        \"username\": tweet.user.username,\n",
    "        \"content\": tweet.rawContent,\n",
    "        \"created_at\": tweet.date,\n",
    "        \"likes\": tweet.likeCount,\n",
    "        \"retweets\": tweet.retweetCount,\n",
    "        \"replies\": tweet.replyCount,\n",
    "        \"parent\": tweet.inReplyToTweetId,\n",
    "        \"photos\": tweet.media.photos,\n",
    "        \"links\": tweet.links,\n",
    "        \"location\": tweet.user.location,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2243463-c0c6-4157-85b2-534a7964cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(tweets):\n",
    "    dfs = {k: tweets2df(v, pase_tweet) for k, v in tweets.items()}\n",
    "\n",
    "    df = pd.concat(list(dfs.values()))\n",
    "    df[\"dia\"] = df.created_at.astype(str).str[:10]\n",
    "    # df[\"mes\"] = df.created_at.astype(str).str[:7]\n",
    "    df[\"any\"] = df.created_at.astype(str).str[:4]\n",
    "    df[\"hora\"] = df.created_at.astype(str).str[11:19]\n",
    "    df.location = df.location.str.lower().str.strip()\n",
    "\n",
    "    df = df.query(\"any == '2025'\").drop_duplicates(subset=\"id\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82f794-7938-4362-ae4f-6bec7a8b47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROWS = 100\n",
    "\n",
    "\n",
    "def merge_dfs(tweets, tweets2, key):\n",
    "    df = tweets2df(tweets[key])\n",
    "    df2 = tweets2df(tweets2[key])\n",
    "    df[\"origin\"] = \"#LaRevuelta\"\n",
    "    df2[\"origin\"] = \"@LaRevuelta_TVE\"\n",
    "    df = pd.concat([df, df2])\n",
    "    df.loc[df.duplicated(subset=\"id\", keep=False), \"origin\"] = \"both\"\n",
    "    df[\"dia\"] = df.created_at.astype(str).str[:10]\n",
    "    # df[\"mes\"] = df.created_at.astype(str).str[:7]\n",
    "    df[\"any\"] = df.created_at.astype(str).str[:4]\n",
    "    df[\"hora\"] = df.created_at.astype(str).str[11:19]\n",
    "    df = (\n",
    "        df[df.content.str.contains(\"#LaRevuelta\") | df.content.str.contains(\"@LaRevuelta_TVE\")]\n",
    "        .drop_duplicates(subset=\"id\")\n",
    "        .query(\"any == '2025'\")\n",
    "        .sort_values(by=[\"replies\", \"retweets\", \"likes\"], ascending=False)  # .iloc[:MAX_ROWS]\n",
    "        .sort_values(by=[\"hora\"])\n",
    "        .drop(columns=[\"created_at\", \"parent\", \"any\", \"origin\"])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d1bc0-4e42-4342-a56e-61e99631df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {k: merge_dfs(tweets, tweets2, k) for k in date_queries.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5513f-0d44-4a5b-bf7b-b214e623d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, df in dfs.items():\n",
    "    print(k, \":\", len(df))\n",
    "    df.to_excel(f\"{k}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
